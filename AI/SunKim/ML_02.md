# ML02 Linear Regression의 hypothesis와 cost 설명





# regression

```
x1 = 1, x2 = 2, x3 = 3

y1 = 1, y2 = 2, y3 = 3
```



## Hypothesis

```
H(x) = Wx + b
```



## Cost / Loss function

```
square(H(x) - y)
```

![image-20230130150213197](C:\Users\admin\Documents\GitHub\TIL\AI\SunKim\ML_02.assets\image-20230130150213197.png)

## Goal

minimize Cost



Gradient descent algorithm 

- 단점(convex function)일 경우에만 답을 찾아준다.